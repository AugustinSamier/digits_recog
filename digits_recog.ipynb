{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "423aeadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2bfbd56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
      "0      1       0       0       0       0       0       0       0       0   \n",
      "1      0       0       0       0       0       0       0       0       0   \n",
      "2      1       0       0       0       0       0       0       0       0   \n",
      "3      4       0       0       0       0       0       0       0       0   \n",
      "4      0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
      "0       0  ...         0         0         0         0         0         0   \n",
      "1       0  ...         0         0         0         0         0         0   \n",
      "2       0  ...         0         0         0         0         0         0   \n",
      "3       0  ...         0         0         0         0         0         0   \n",
      "4       0  ...         0         0         0         0         0         0   \n",
      "\n",
      "   pixel780  pixel781  pixel782  pixel783  \n",
      "0         0         0         0         0  \n",
      "1         0         0         0         0  \n",
      "2         0         0         0         0  \n",
      "3         0         0         0         0  \n",
      "4         0         0         0         0  \n",
      "\n",
      "[5 rows x 785 columns]\n"
     ]
    }
   ],
   "source": [
    "trainDf=pd.read_csv(\"train.csv\")\n",
    "print(trainDf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcd59e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n"
     ]
    }
   ],
   "source": [
    "print(trainDf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be20b5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of y_train : 42000\n",
      "Size of X_train : (42000, 28, 28)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ytrain=trainDf[\"label\"].values\n",
    "X_train=trainDf.iloc[:,1:].values.reshape(-1,28,28)\n",
    "X_train=X_train.astype(np.float32)/255.0\n",
    "print(f\"Size of y_train : {len(ytrain)}\\nSize of X_train : {X_train.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70e1a84a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0],cmap=\"gray\")\n",
    "plt.title(\"Premier sample\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef179dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sobelX=np.array([\n",
    "    [-1,0,1],\n",
    "    [-2,0,2],\n",
    "    [-1,0,1]\n",
    "]) #detection de bords horizontaux\n",
    "\n",
    "sobelY=np.array([\n",
    "    [-1,-2,-1],\n",
    "    [0,0,0],\n",
    "    [1,2,1]\n",
    "]) #detection de bords verticaux\n",
    "\n",
    "prewittX=np.array([\n",
    "    [-1,0,1],\n",
    "    [-1,0,1],\n",
    "    [-1,0,1]\n",
    "]) #detection de bords horizontaux (comme sobelX mais moins marqué)\n",
    "\n",
    "laplacien=np.array([\n",
    "    [0,-1,0],\n",
    "    [-1,4,-1],\n",
    "    [0,-1,0]\n",
    "]) #detection de bords toutes directions\n",
    "\n",
    "laplacienPlus=np.array([\n",
    "    [-1,-1,-1],\n",
    "    [-1,8,-1],\n",
    "    [-1,-1,-1]\n",
    "]) #detection de bords toutes directions (laplacien plus marqué)\n",
    "\n",
    "blur=np.array([\n",
    "    [1/9,1/9,1/9],\n",
    "    [1/9,1/9,1/9],\n",
    "    [1/9,1/9,1/9]\n",
    "]) #flou\n",
    "\n",
    "gaussien=np.array([\n",
    "    [1/16,2/16,1/16],\n",
    "    [2/16,4/16,2/16],\n",
    "    [1/16,2/16,1/16]\n",
    "]) #flou plus doux\n",
    "\n",
    "sharpen=np.array([\n",
    "    [0,-1,0],\n",
    "    [-1,5,-1],\n",
    "    [0,-1,0]\n",
    "]) #accentuation contours\n",
    "\n",
    "\n",
    "avrPooling2dKernel=np.array([\n",
    "    [1/4,1/4],\n",
    "    [1/4,1/4]\n",
    "]) #Fait la moyenne des 4 éléments = avrPooling de dim 2,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb5a3e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(img,pad_size=0):\n",
    "    if pad_size==0:\n",
    "        return img\n",
    "    else:\n",
    "        newImg=np.zeros((img.shape[0]+2*pad_size,img.shape[1]+2*pad_size))\n",
    "        for w in range(pad_size,newImg.shape[0]-pad_size):\n",
    "            for h in range(pad_size,newImg.shape[1]-pad_size):\n",
    "                newImg[w][h]=img[w-pad_size][h-pad_size]\n",
    "        return newImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80b80d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createRandomKernels(nb_kernels,dim):\n",
    "    kernels=[]\n",
    "    for i in range(nb_kernels):\n",
    "        kernels.append(np.random.randn(dim[0],dim[1]))\n",
    "    return kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1796c8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxPooling2d(images,dim):\n",
    "    maxed=[]\n",
    "    for img in images:\n",
    "        newImg=np.zeros((((img.shape[0]-dim[0])//dim[0])+1,((img.shape[1]-dim[1])//dim[1])+1))\n",
    "        for w in range(newImg.shape[0]):\n",
    "            for h in range(newImg.shape[1]):\n",
    "                cur_max=float(\"-inf\")\n",
    "                for kw in range(dim[0]):\n",
    "                    for kh in range(dim[1]):\n",
    "                        if img[w*dim[0]+kw][h*dim[1]+kh]>cur_max:\n",
    "                            cur_max=img[w*dim[0]+kw][h*dim[1]+kh]\n",
    "                newImg[w][h]=cur_max\n",
    "        maxed.append(newImg)\n",
    "    return maxed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "671dcea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def averagePooling2d(images,dim):\n",
    "    averaged=[]\n",
    "    for img in images:\n",
    "        newImg=np.zeros((((img.shape[0]-dim[0])//dim[0])+1,((img.shape[1]-dim[1])//dim[1])+1))\n",
    "        for w in range(newImg.shape[0]):\n",
    "            for h in range(newImg.shape[1]):\n",
    "                avr=0\n",
    "                for kw in range(dim[0]):\n",
    "                    for kh in range(dim[1]):\n",
    "                        avr+=img[w*dim[0]+kw][h*dim[1]+kh]\n",
    "                newImg[w][h]=avr/(dim[0]*dim[1])\n",
    "        averaged.append(newImg)\n",
    "    return averaged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4328a65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(inputs,out_dim,kernel_size,pad_size=0,stride=1,specificKernel=None,extractKernels=False):\n",
    "    outputs=[]\n",
    "    kernels=[]\n",
    "    padded=[]\n",
    "    for img in inputs:\n",
    "        padded.append(padding(img,pad_size=pad_size))\n",
    "    for resultante in range(out_dim):\n",
    "        if specificKernel is not None:\n",
    "            if len(specificKernel)!=len(inputs):\n",
    "                if len(specificKernel)>len(inputs):\n",
    "                    k=specificKernel[:len(inputs)]\n",
    "                else:\n",
    "                    k=specificKernel*(len(inputs)//len(specificKernel))+specificKernel[:len(inputs)%len(specificKernel)]\n",
    "            else:\n",
    "                k=specificKernel\n",
    "        else:\n",
    "            k=createRandomKernels(len(inputs),kernel_size)\n",
    "        kernels.append(k)\n",
    "\n",
    "        newImg=np.zeros((((padded[0].shape[0]-kernel_size[0])//stride)+1,((padded[0].shape[1]-kernel_size[1])//stride)+1))\n",
    "\n",
    "        for w in range(newImg.shape[0]):\n",
    "            for h in range(newImg.shape[1]):\n",
    "                res=0\n",
    "                for kw in range(kernel_size[0]):\n",
    "                    for kh in range(kernel_size[1]):\n",
    "                        tot=0\n",
    "                        for i,img in enumerate(padded):\n",
    "                            tot+=k[i][kw][kh]*img[w*stride+kw][h*stride+kh]\n",
    "                        res+=tot\n",
    "                newImg[w][h]=res\n",
    "\n",
    "        outputs.append(newImg)\n",
    "    \n",
    "    if extractKernels:\n",
    "        return outputs,kernels\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62bbe765",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m conv1\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m images:\n\u001b[1;32m----> 6\u001b[0m     conv\u001b[38;5;241m=\u001b[39m(conv2d([img],\u001b[38;5;241m6\u001b[39m,(\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m5\u001b[39m),pad_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m      7\u001b[0m     avr\u001b[38;5;241m=\u001b[39maveragePooling2d(conv,(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m      8\u001b[0m     conv2\u001b[38;5;241m=\u001b[39mconv2d(avr,\u001b[38;5;241m16\u001b[39m,(\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m5\u001b[39m),pad_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[13], line 29\u001b[0m, in \u001b[0;36mconv2d\u001b[1;34m(inputs, out_dim, kernel_size, pad_size, stride, specificKernel, extractKernels)\u001b[0m\n\u001b[0;32m     27\u001b[0m         tot\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     28\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i,img \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(padded):\n\u001b[1;32m---> 29\u001b[0m             tot\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39mk[i][kw][kh]\u001b[38;5;241m*\u001b[39mimg[w\u001b[38;5;241m*\u001b[39mstride\u001b[38;5;241m+\u001b[39mkw][h\u001b[38;5;241m*\u001b[39mstride\u001b[38;5;241m+\u001b[39mkh]\n\u001b[0;32m     30\u001b[0m         res\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39mtot\n\u001b[0;32m     31\u001b[0m newImg[w][h]\u001b[38;5;241m=\u001b[39mres\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kernels=[sobelX,sobelY,prewittX,laplacien,laplacienPlus,blur,gaussien,sharpen]\n",
    "#si je veux passer une image BGR il faut d'abord la passer en gris ou séparer les cannaux en plusieurs images\n",
    "images=X_train[:20000]\n",
    "conv1=[]\n",
    "for img in images:\n",
    "    conv=(conv2d([img],6,(5,5),pad_size=0))\n",
    "    avr=averagePooling2d(conv,(2,2))\n",
    "    conv2=conv2d(avr,16,(5,5),pad_size=0)\n",
    "    avr2=averagePooling2d(conv2,(2,2))\n",
    "    conv1.append(avr2)\n",
    "for i in range(1):\n",
    "    for m in range(len(conv1[i])):\n",
    "        plt.imshow(conv1[i][m],cmap=\"gray\")\n",
    "        plt.title(f\"Convolution {m+1} of image {i+1}\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6026eca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat=[]\n",
    "for i in range(len(conv1)):\n",
    "    fla=[]\n",
    "    for convs in conv1[i]:\n",
    "        fla.append(convs.flatten())\n",
    "    ca=np.concatenate(fla)\n",
    "    flat.append(ca)\n",
    "flat=np.array(flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ad4f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 256)\n"
     ]
    }
   ],
   "source": [
    "print(flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19e2a6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createRandomBias(nb_neurones):\n",
    "    bias=np.random.randn(nb_neurones)\n",
    "    return bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c79edb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createRandomWeights(nb_inputs,nb_neurones):\n",
    "    limit=np.sqrt(6/(nb_inputs+nb_neurones))\n",
    "    weights=np.random.uniform(-limit,limit,size=(nb_neurones,nb_inputs))\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3012f54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denseLayer(inputs,nb_neurones,fonctionActivation=None,specificBias=None,specificWeights=None,returnWeightsAndBias=False,alpha=0.01):\n",
    "    bias=[]\n",
    "    weights=[]\n",
    "    outputs=[]\n",
    "    if specificBias is None:\n",
    "        bias=createRandomBias(nb_neurones)\n",
    "    elif len(specificBias)==nb_neurones:\n",
    "        bias=specificBias\n",
    "    else:\n",
    "        print(f\"Erreur : le nombre de biais assigné ({len(specificBias)}) n'est pas équivalent au nombre de neurones : {nb_neurones}\")\n",
    "    if specificWeights is None:\n",
    "        weights=createRandomWeights(len(inputs),nb_neurones)\n",
    "    elif len(specificWeights)==nb_neurones and len(specificWeights[0])==len(inputs):\n",
    "        weights=specificWeights\n",
    "    else:\n",
    "        print(f\"Erreur : le nombre de poids assigné n'est pas correct : {len(specificWeights)} pour {nb_neurones} neurones et {len(specificWeights[0])} pour {len(inputs)} inputs.\")\n",
    "    for neurone in range(nb_neurones):\n",
    "        result=0\n",
    "        for inpu in range(len(inputs)):\n",
    "            result+=(inputs[inpu]*weights[neurone][inpu])\n",
    "        result+=bias[neurone]\n",
    "        if fonctionActivation==\"ReLU\":\n",
    "            result=max(0,result)\n",
    "        if fonctionActivation==\"Leaky ReLU\":\n",
    "            if result<0:\n",
    "                result=alpha*result\n",
    "        if fonctionActivation==\"Sigmoid\":\n",
    "            result=(1/(1+np.exp(-result)))\n",
    "        if fonctionActivation==\"Tanh\":\n",
    "            result=((np.exp(result)-np.exp(-result))/(np.exp(result)+np.exp(-result)))\n",
    "        outputs.append(result)\n",
    "    outputs=np.array(outputs)\n",
    "    if fonctionActivation==\"Softmax\":\n",
    "        exps=np.exp(outputs-np.max(outputs))\n",
    "        #outputs=exps/np.sum(exps)\n",
    "    if returnWeightsAndBias:\n",
    "        return outputs,weights,bias\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fce88c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.19131536 -0.80542362  1.27820362]\n",
      "[0.1603603 0.2495718]\n",
      "[0.14049516 0.64820591 0.21129893]\n"
     ]
    }
   ],
   "source": [
    "test=np.random.randn(3)\n",
    "print(test)\n",
    "outputs=denseLayer(test,2,fonctionActivation=\"Leaky ReLU\")\n",
    "print(outputs)\n",
    "outputs2=denseLayer(outputs,3,fonctionActivation=\"Softmax\")\n",
    "print(outputs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e51df651",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=[]\n",
    "for y in range(len(ytrain)):\n",
    "    yt=np.zeros(10)\n",
    "    yt[ytrain[y]]=1\n",
    "    y_train.append(yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "361ad00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4841ea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights1,bias1=createRandomWeights(256,128),createRandomBias(128)\n",
    "weights2,bias2=createRandomWeights(128,84),createRandomBias(84)\n",
    "weights3,bias3=createRandomWeights(84,10),createRandomBias(10)\n",
    "f1=\"ReLU\"\n",
    "f2=\"ReLU\"\n",
    "#256 -> 128 -> 84 -> 10\n",
    "def forward(inputs,weights1,bias1,weights2,bias2,weights3,bias3,f1,f2):\n",
    "    outputs1,outputs2,outputs3=[],[],[]\n",
    "    for i,inp in enumerate(inputs):\n",
    "        outputs1.append(denseLayer(inp,len(weights1),fonctionActivation=f1,specificBias=bias1,specificWeights=weights1))\n",
    "        outputs2.append(denseLayer(outputs1[i],len(weights2),fonctionActivation=f2,specificBias=bias2,specificWeights=weights2))\n",
    "        outputs3.append(denseLayer(outputs2[i],len(weights3),fonctionActivation=\"Softmax\",specificBias=bias3,specificWeights=weights3))\n",
    "    return outputs1,outputs2,outputs3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7681695",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs1,outputs2,outputs3=forward(flat,weights1,bias1,weights2,bias2,weights3,bias3,f1,f2)\n",
    "\n",
    "print(outputs3[0])\n",
    "print(outputs3[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2500913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1999853005728788\n"
     ]
    }
   ],
   "source": [
    "MSE=[]\n",
    "for out in range(len(outputs3)):\n",
    "    MSE.append((np.sum((outputs3[out]-y_train[out])**2))/10)\n",
    "print(MSE[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b3cb2392",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DMSE/DWx = DMSE/DYx * DYx/DZx * DZx/DWx pour les poids entre la dernière couche et la couche de sortie\n",
    "#fonction d'activation : Softmax\n",
    "#on fait 84 -> 10 donc chaque output a 84 poids connectés à elle\n",
    "#DMSE/Dweights3[0][0] -> pour actualier le premier poids, celui entre le premier neurone de la couche précédente et la première output.\n",
    "#= DMSE/Doutputs3[0] (Doutputs3[0] = softmax(Z0)+bias3[0]) * Doutputs3[0]/DZ[0] * DZ[0]/Dweights3[0][0] Z[0] = a0*weights3[0][0]+a0*weights3[0][1]+...+bias[0], \n",
    "#a0 étant l'output du premier neurone de la couche précédente et bias3 le biais du premier neurone.\n",
    "#Ainsi MSE=(1/10)*SOMME((outputs3-y_train[0])**2) = 1/10 * ((outputs3[0]-y_train[0][0])²+(outputs3[0]-y_train[0][0])²+...) donc DMSE/Doutputs3[0] = 1/10 * 2 * 1 * (outputs3[0]-y_train[0][0])\n",
    "#Doutputs3[0]/DZ[0] = Dsoftmax(Z0)/DZ0 -> softmax(Z0) = exp(Z0)/SOMME0->n(exp(Zn)) Dsoftmax(Z0)/DZ0 est de la forme (U/V)' donc = (exp(Z0)*(SOMME)-exp(Z0)²)/SOMME² = exp(Z0)*(SOMME-exp(Z0))/SOMME²\n",
    "#sachant que outputs3[0]=exp(Z0)/SOMME alors Dsoftmax(Z0)/DZ0= outputs3[0]*((SOMME/SOMME)-(exp(Z0)/SOMME)) = outputs3[0]*(1-outputs3[0]) = outputes3[0] - outputs3[0]**2\n",
    "#enfin, DZ0/Dweights3[0][0]= D(outputs2[0]*weights3[0][0]+outputs2[0]*weights3[0][1]...)/Dweights3[0][0] = outputs2[0]\n",
    "#en conclusion: DMSE/Dweights3[0][0]=1/5 * (outputs3[0]-y_train[0][0]) * (outputs3[0]-outputs3[0]**2) * outputs2[0]\n",
    "#et pour actualiser weights3[0][1] : 1/5 * (outputs3[0]-y_train[0][0]) * (outputs3[0]-outputs3[0]**2) * outputs2[1] jusqu'à outputs2[83] pour weights3[0][83]\n",
    "#pour weights3[1][0] : 1/5 * (outputs3[1]-y_train[0][1]) * (outputs3[1]-outputs3[1]**2) * outputs2[0] etc...\n",
    "#pour weights2[0][0]: (1/5 * (outputs3[1]-y_train[0][1]) * (outputs3[1]-outputs3[1]**2)+1/5 * (outputs3[2]-y_train[0][2]) * (outputs3[2]-outputs3[2]**2)...)* Da/Dz-1\n",
    "\n",
    "def backPropagation(flat,outputs1,outputs2,outputs3,weights1,weights2,weights3,bias1,bias2,bias3,alpha=0.001,f1=\"ReLU\",f2=\"ReLU\"):\n",
    "    gradSoft=np.zeros(outputs3[0].shape[0])\n",
    "    gradB3=np.zeros(outputs3[0].shape[0])\n",
    "    gradB2=np.zeros(outputs2[0].shape[0])\n",
    "    gradB1=np.zeros(outputs1[0].shape[0])\n",
    "    gradW3=np.zeros(weights3.shape)\n",
    "    gradWeights3=np.zeros(weights3.shape)\n",
    "    gradW2=np.zeros(weights2.shape)\n",
    "    gradWeights2=np.zeros(weights2.shape)\n",
    "    gradW1=np.zeros(weights1.shape)\n",
    "    gradWeights1=np.zeros(weights1.shape)\n",
    "    for img in range(len(outputs3)):\n",
    "        gradA2=np.zeros(outputs2[img].shape[0])\n",
    "        gradA1=np.zeros(outputs1[img].shape[0])\n",
    "        gradMSE=(2/len(outputs3[img]))*(outputs3[img]-y_train[img])\n",
    "        #gradSoft=gradMSE*outputs3[img]*(1-outputs3[img])\n",
    "        gradSoft=gradMSE\n",
    "        for out3 in range(len(outputs3[img])): #chaque neurone de sortie (10)\n",
    "            for out2 in range(len(outputs2[img])): #chaque output précédent\n",
    "                gradWeights3[out3][out2]=gradSoft[out3]*outputs2[img][out2]\n",
    "        \n",
    "        for out2 in range(len(outputs2[img])):\n",
    "            for out3 in range(len(outputs3[img])):\n",
    "                if f2==\"ReLU\":\n",
    "                    if outputs2[img][out2]>0:\n",
    "                        gradA2[out2]+=gradSoft[out3]*weights3[out3][out2]\n",
    "                    else:\n",
    "                        gradA2[out2]+=0\n",
    "        \n",
    "        for out2 in range(len(outputs2[img])):\n",
    "            for out1 in range(len(outputs1[img])):\n",
    "                gradWeights2[out2][out1]=gradA2[out2]*outputs1[img][out1]\n",
    "        \n",
    "        for out1 in range(len(outputs1[img])):\n",
    "            for out2 in range(len(outputs2[img])):\n",
    "                if f1==\"ReLU\":\n",
    "                    if outputs1[img][out1]>0:\n",
    "                        gradA1[out1]+=gradA2[out2]*weights2[out2][out1]\n",
    "                    else:\n",
    "                        gradA1[out1]+=0\n",
    "        \n",
    "        for out1 in range(len(outputs1[img])):\n",
    "            for fla in range(len(flat[img])):\n",
    "                gradWeights1[out1][fla]=gradA1[out1]*flat[img][fla]\n",
    "\n",
    "        gradW1+=gradWeights1/len(outputs3)\n",
    "        gradB1+=gradA1/len(outputs3)\n",
    "        gradW2+=gradWeights2/len(outputs3)\n",
    "        gradB2+=gradA2/len(outputs3)\n",
    "        gradB3+=gradSoft/len(outputs3)\n",
    "        gradW3+=gradWeights3/len(outputs3)\n",
    "\n",
    "    newWeights3=weights3-alpha*gradW3\n",
    "    newWeights2=weights2-alpha*gradW2\n",
    "    newWeights1=weights1-alpha*gradW1\n",
    "    newBias3=bias3-alpha*gradB3\n",
    "    newBias2=bias2-alpha*gradB2\n",
    "    newBias1=bias1-alpha*gradB1\n",
    "\n",
    "    return newWeights1,newBias1,newWeights2,newBias2,newWeights3,newBias3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "956fb65f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'flat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m newWeights1,newBias1,newWeights2,newBias2,newWeights3,newBias3\u001b[38;5;241m=\u001b[39mbackPropagation(flat,outputs1,outputs2,outputs3,weights1,weights2,weights3,bias1,bias2,bias3,alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m,f1\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReLU\u001b[39m\u001b[38;5;124m\"\u001b[39m,f2\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReLU\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'flat' is not defined"
     ]
    }
   ],
   "source": [
    "newWeights1,newBias1,newWeights2,newBias2,newWeights3,newBias3=backPropagation(flat,outputs1,outputs2,outputs3,weights1,weights2,weights3,bias1,bias2,bias3,alpha=0.001,f1=\"ReLU\",f2=\"ReLU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff19795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old weight : 0.07393104184753962 , new : 0.07393104246500314\n"
     ]
    }
   ],
   "source": [
    "print(f\"Old weight : {weights1[0][0]} , new : {newWeights1[0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "80313caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(nb_epoch,inputs,y_label,weights1,bias1,weights2,bias2,weights3,bias3,f1,f2):\n",
    "    for e in range(nb_epoch-1):\n",
    "        outputs1,outputs2,outputs3=forward(inputs,weights1,bias1,weights2,bias2,weights3,bias3,f1,f2)\n",
    "        MSE=[]\n",
    "        for out in range(len(outputs3)):\n",
    "            MSE.append((np.sum((outputs3[out]-y_label[out])**2))/10)\n",
    "        print(f\"epoch : {e+1} : {np.sum(MSE)}\")\n",
    "        weights1,bias1,weights2,bias2,weights3,bias3=backPropagation(inputs,outputs1,outputs2,outputs3,weights1,weights2,weights3,bias1,bias2,bias3,alpha=0.01,f1=\"ReLU\",f2=\"ReLU\")\n",
    "\n",
    "    outputs1,outputs2,outputs3=forward(inputs,weights1,bias1,weights2,bias2,weights3,bias3,f1,f2)\n",
    "    MSE=[]\n",
    "    for out in range(len(outputs3)):\n",
    "        MSE.append((np.sum((outputs3[out]-y_label[out])**2))/10)\n",
    "    print(f\"Last MSE : {np.sum(MSE)}\")\n",
    "    return weights1,bias1,weights2,bias2,weights3,bias3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "97a159c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "testInputs=np.zeros((100,10))\n",
    "y_testput=np.zeros((100,10))\n",
    "print(testInputs[0])\n",
    "for i in range(100):\n",
    "    testInputs[i][i%10]=1\n",
    "    y_testput[i][i%10]=1\n",
    "print(testInputs[0],y_testput[0])\n",
    "print(testInputs[1],y_testput[1])\n",
    "MSE=[]\n",
    "for out in range(len(testInputs)):\n",
    "    MSE.append((np.sum((testInputs[out]-y_testput[out])**2))/10)\n",
    "print(np.sum(MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "919cba1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(testInputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f694c7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixedtestweights1,fixedtestbias1=createRandomWeights(10,10),createRandomBias(10)\n",
    "fixedtestweights2,fixedtestbias2=createRandomWeights(10,10),createRandomBias(10)\n",
    "fixedtestweights3,fixedtestbias3=createRandomWeights(10,10),createRandomBias(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "af317f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1 : 33.1856603444152\n",
      "epoch : 2 : 28.658039592186924\n",
      "epoch : 3 : 25.01719321662693\n",
      "epoch : 4 : 22.045956060230203\n",
      "epoch : 5 : 19.590169131109885\n",
      "epoch : 6 : 17.537809279469084\n",
      "epoch : 7 : 15.805808642613066\n",
      "epoch : 8 : 14.331471577090726\n",
      "epoch : 9 : 13.066734689938517\n",
      "epoch : 10 : 11.97426194283182\n",
      "epoch : 11 : 11.024623313457056\n",
      "epoch : 12 : 10.194430857671714\n",
      "epoch : 13 : 9.464869046296302\n",
      "epoch : 14 : 8.820402810635297\n",
      "epoch : 15 : 8.24838331108878\n",
      "epoch : 16 : 7.738921916500266\n",
      "epoch : 17 : 7.283472556014046\n",
      "epoch : 18 : 6.874889305581125\n",
      "epoch : 19 : 6.507160364809472\n",
      "epoch : 20 : 6.17516307099446\n",
      "epoch : 21 : 5.874502722215966\n",
      "epoch : 22 : 5.601613678736302\n",
      "epoch : 23 : 5.353314378259161\n",
      "epoch : 24 : 5.12686077932893\n",
      "epoch : 25 : 4.919876418075343\n",
      "epoch : 26 : 4.730295149314793\n",
      "epoch : 27 : 4.556314009472602\n",
      "epoch : 28 : 4.396354207364798\n",
      "epoch : 29 : 4.2490286804758455\n",
      "epoch : 30 : 4.113114984485457\n",
      "epoch : 31 : 3.9875325381112807\n",
      "epoch : 32 : 3.87132344258493\n",
      "epoch : 33 : 3.7636362490573423\n",
      "epoch : 34 : 3.6637121681645994\n",
      "epoch : 35 : 3.5708733115206983\n",
      "epoch : 36 : 3.484512630791863\n",
      "epoch : 37 : 3.4040852806062696\n",
      "epoch : 38 : 3.3291011801871826\n",
      "epoch : 39 : 3.2591185878164883\n",
      "epoch : 40 : 3.1937385340073563\n",
      "epoch : 41 : 3.132599985116585\n",
      "epoch : 42 : 3.0753756302506963\n",
      "epoch : 43 : 3.0217682016493748\n",
      "epoch : 44 : 2.971507253002153\n",
      "epoch : 45 : 2.924346331952118\n",
      "epoch : 46 : 2.880060492827913\n",
      "epoch : 47 : 2.8384441037928143\n",
      "epoch : 48 : 2.7993089094045076\n",
      "epoch : 49 : 2.762482315280685\n",
      "epoch : 50 : 2.72780586635732\n",
      "epoch : 51 : 2.695158033735698\n",
      "epoch : 52 : 2.664375618028865\n",
      "epoch : 53 : 2.635336384549682\n",
      "epoch : 54 : 2.607926622955878\n",
      "epoch : 55 : 2.582041279423123\n",
      "epoch : 56 : 2.5575831886695304\n",
      "epoch : 57 : 2.5344623841030898\n",
      "epoch : 58 : 2.512595477165662\n",
      "epoch : 59 : 2.4919050980737865\n",
      "epoch : 60 : 2.472319391127906\n",
      "epoch : 61 : 2.45377155860089\n",
      "epoch : 62 : 2.4361994479433093\n",
      "epoch : 63 : 2.419545177673282\n",
      "epoch : 64 : 2.4037547978665743\n",
      "epoch : 65 : 2.3887779816397137\n",
      "epoch : 66 : 2.374567744435156\n",
      "epoch : 67 : 2.3610801882812433\n",
      "epoch : 68 : 2.3482742685182076\n",
      "epoch : 69 : 2.3361115807607122\n",
      "epoch : 70 : 2.3245561661127185\n",
      "epoch : 71 : 2.3135743328663105\n",
      "epoch : 72 : 2.303134493106193\n",
      "epoch : 73 : 2.293207012809425\n",
      "epoch : 74 : 2.2837640741782272\n",
      "epoch : 75 : 2.2747795490749105\n",
      "epoch : 76 : 2.2662288825443064\n",
      "epoch : 77 : 2.258088985512276\n",
      "epoch : 78 : 2.250322089209125\n",
      "epoch : 79 : 2.24279586103176\n",
      "epoch : 80 : 2.235620447218106\n",
      "epoch : 81 : 2.2287776558640977\n",
      "epoch : 82 : 2.2222503382751464\n",
      "epoch : 83 : 2.21602232190866\n",
      "epoch : 84 : 2.21007834821185\n",
      "epoch : 85 : 2.2044040149489534\n",
      "epoch : 86 : 2.19898572264973\n",
      "epoch : 87 : 2.193810624844907\n",
      "epoch : 88 : 2.188866581784667\n",
      "epoch : 89 : 2.1841421173636366\n",
      "epoch : 90 : 2.1796263790005104\n",
      "epoch : 91 : 2.1753091002426386\n",
      "epoch : 92 : 2.1711805658859995\n",
      "epoch : 93 : 2.1672315794190875\n",
      "epoch : 94 : 2.163453432615653\n",
      "epoch : 95 : 2.1598378771160607\n",
      "epoch : 96 : 2.156377097850492\n",
      "epoch : 97 : 2.153063688169402\n",
      "epoch : 98 : 2.1498906265577262\n",
      "epoch : 99 : 2.146851254819387\n",
      "epoch : 100 : 2.143939257627793\n",
      "epoch : 101 : 2.1411486433463756\n",
      "epoch : 102 : 2.1384737260307807\n",
      "epoch : 103 : 2.1359091085312487\n",
      "epoch : 104 : 2.133449666620065\n",
      "epoch : 105 : 2.1310905340746893\n",
      "epoch : 106 : 2.128827088652492\n",
      "epoch : 107 : 2.1266549388978238\n",
      "epoch : 108 : 2.1245699117265904\n",
      "epoch : 109 : 2.12256804073753\n",
      "epoch : 110 : 2.1206455552031462\n",
      "epoch : 111 : 2.118798869696622\n",
      "epoch : 112 : 2.117024574314225\n",
      "epoch : 113 : 2.115319425455549\n",
      "epoch : 114 : 2.113680337126637\n",
      "epoch : 115 : 2.112104372733437\n",
      "epoch : 116 : 2.110588737335338\n",
      "epoch : 117 : 2.109130770330574\n",
      "epoch : 118 : 2.107727938547227\n",
      "epoch : 119 : 2.106377829715329\n",
      "epoch : 120 : 2.1050781462971973\n",
      "epoch : 121 : 2.1038266996546633\n",
      "epoch : 122 : 2.1026214045332523\n",
      "epoch : 123 : 2.101460273844677\n",
      "epoch : 124 : 2.1003414137302143\n",
      "epoch : 125 : 2.0992630188886525\n",
      "epoch : 126 : 2.0982233681535427\n",
      "epoch : 127 : 2.0972208203054414\n",
      "epoch : 128 : 2.0962538101057433\n",
      "epoch : 129 : 2.0953208445395286\n",
      "epoch : 130 : 2.094420499255631\n",
      "epoch : 131 : 2.0935514151928616\n",
      "epoch : 132 : 2.0927122953819857\n",
      "epoch : 133 : 2.0919019019136953\n",
      "epoch : 134 : 2.0911190530633936\n",
      "epoch : 135 : 2.0903626205641745\n",
      "epoch : 136 : 2.0896315270198635\n",
      "epoch : 137 : 2.0889247434504967\n",
      "epoch : 138 : 2.088241286963051\n",
      "epoch : 139 : 2.087580218540641\n",
      "epoch : 140 : 2.0869406409438165\n",
      "epoch : 141 : 2.0863216967179583\n",
      "epoch : 142 : 2.085722566301086\n",
      "epoch : 143 : 2.0851424662267615\n",
      "epoch : 144 : 2.0845806474170225\n",
      "epoch : 145 : 2.0840363935606194\n",
      "epoch : 146 : 2.0835090195720483\n",
      "epoch : 147 : 2.0829978701271457\n",
      "epoch : 148 : 2.0825023182712563\n",
      "epoch : 149 : 2.0820217640961824\n",
      "epoch : 150 : 2.081555633482344\n",
      "epoch : 151 : 2.0811033769027842\n",
      "epoch : 152 : 2.0806644682858155\n",
      "epoch : 153 : 2.0802384039333024\n",
      "epoch : 154 : 2.079824701491719\n",
      "epoch : 155 : 2.0794228989732835\n",
      "epoch : 156 : 2.0790325538246175\n",
      "epoch : 157 : 2.078653242040507\n",
      "epoch : 158 : 2.0782845573204862\n",
      "epoch : 159 : 2.077926110266067\n",
      "epoch : 160 : 2.077577527616568\n",
      "epoch : 161 : 2.0772384515215996\n",
      "epoch : 162 : 2.0769085388483637\n",
      "epoch : 163 : 2.076587460522018\n",
      "epoch : 164 : 2.076274900897467\n",
      "epoch : 165 : 2.075970557160991\n",
      "epoch : 166 : 2.07567413876025\n",
      "epoch : 167 : 2.075385366861238\n",
      "epoch : 168 : 2.0751039738308585\n",
      "epoch : 169 : 2.074829702743864\n",
      "epoch : 170 : 2.0745623069129344\n",
      "epoch : 171 : 2.074301549440785\n",
      "epoch : 172 : 2.0740472027931967\n",
      "epoch : 173 : 2.073799048391963\n",
      "epoch : 174 : 2.0735568762267618\n",
      "epoch : 175 : 2.0733204844850466\n",
      "epoch : 176 : 2.0730896791990645\n",
      "epoch : 177 : 2.072864273909176\n",
      "epoch : 178 : 2.0726440893426874\n",
      "epoch : 179 : 2.072428953107436\n",
      "epoch : 180 : 2.072218699399432\n",
      "epoch : 181 : 2.0720131687238554\n",
      "epoch : 182 : 2.071812207628789\n",
      "epoch : 183 : 2.071615668451062\n",
      "epoch : 184 : 2.0714234090736277\n",
      "epoch : 185 : 2.071235292693925\n",
      "epoch : 186 : 2.0710511876026922\n",
      "epoch : 187 : 2.07087096697275\n",
      "epoch : 188 : 2.070694508657262\n",
      "epoch : 189 : 2.0705216949970358\n",
      "epoch : 190 : 2.070352412636431\n",
      "epoch : 191 : 2.0701865523474665\n",
      "epoch : 192 : 2.0700240088617483\n",
      "epoch : 193 : 2.069864680709838\n",
      "epoch : 194 : 2.069708470067717\n",
      "epoch : 195 : 2.069555282610024\n",
      "epoch : 196 : 2.069405027369728\n",
      "epoch : 197 : 2.0692576166039576\n",
      "epoch : 198 : 2.069112965665686\n",
      "epoch : 199 : 2.0689709928810065\n",
      "epoch : 200 : 2.0688316194317307\n",
      "epoch : 201 : 2.0686947692430784\n",
      "epoch : 202 : 2.068560368876205\n",
      "epoch : 203 : 2.068428347425359\n",
      "epoch : 204 : 2.068298636419449\n",
      "epoch : 205 : 2.068171169727819\n",
      "epoch : 206 : 2.068045883470037\n",
      "epoch : 207 : 2.0679227159295217\n",
      "epoch : 208 : 2.067801607470826\n",
      "epoch : 209 : 2.067682500460406\n",
      "epoch : 210 : 2.0675653391907307\n",
      "epoch : 211 : 2.0674500698075704\n",
      "epoch : 212 : 2.067336640240323\n",
      "epoch : 213 : 2.067225000135245\n",
      "epoch : 214 : 2.0671151007914506\n",
      "epoch : 215 : 2.067006895099561\n",
      "epoch : 216 : 2.066900337482879\n",
      "epoch : 217 : 2.0667953838409865\n",
      "epoch : 218 : 2.066691991495639\n",
      "epoch : 219 : 2.066590119138879\n",
      "epoch : 220 : 2.066489726783248\n",
      "epoch : 221 : 2.0663907757140216\n",
      "epoch : 222 : 2.0662932284433655\n",
      "epoch : 223 : 2.0661970486663366\n",
      "epoch : 224 : 2.0661022012186447\n",
      "epoch : 225 : 2.0660086520361003\n",
      "epoch : 226 : 2.0659163681156754\n",
      "epoch : 227 : 2.065825317478096\n",
      "epoch : 228 : 2.065735469131923\n",
      "epoch : 229 : 2.0656467930390368\n",
      "epoch : 230 : 2.0655592600814687\n",
      "epoch : 231 : 2.0654728420295356\n",
      "epoch : 232 : 2.0653875115112017\n",
      "epoch : 233 : 2.065303241982628\n",
      "epoch : 234 : 2.0652200076998573\n",
      "epoch : 235 : 2.065137783691585\n",
      "epoch : 236 : 2.0650565457329684\n",
      "epoch : 237 : 2.0649762703204346\n",
      "epoch : 238 : 2.0648969346474377\n",
      "epoch : 239 : 2.0648185165811395\n",
      "epoch : 240 : 2.0647409946399597\n",
      "epoch : 241 : 2.064664347971966\n",
      "epoch : 242 : 2.064588556334076\n",
      "epoch : 243 : 2.0645136000720234\n",
      "epoch : 244 : 2.064439460101069\n",
      "epoch : 245 : 2.064366117887422\n",
      "epoch : 246 : 2.064293555430339\n",
      "epoch : 247 : 2.0642217552448767\n",
      "epoch : 248 : 2.0641507003452784\n",
      "epoch : 249 : 2.064080374228949\n",
      "epoch : 250 : 2.06401076086102\n",
      "epoch : 251 : 2.0639418446594595\n",
      "epoch : 252 : 2.0638736104807203\n",
      "epoch : 253 : 2.063806043605893\n",
      "epoch : 254 : 2.063739129727356\n",
      "epoch : 255 : 2.0636728549358887\n",
      "epoch : 256 : 2.0636072057082457\n",
      "epoch : 257 : 2.0635421688951605\n",
      "epoch : 258 : 2.0634777317097663\n",
      "epoch : 259 : 2.0634138817164223\n",
      "epoch : 260 : 2.063350606819923\n",
      "epoch : 261 : 2.0632878952550797\n",
      "epoch : 262 : 2.0632257355766566\n",
      "epoch : 263 : 2.0631641166496566\n",
      "epoch : 264 : 2.063103027639926\n",
      "epoch : 265 : 2.0630424580050875\n",
      "epoch : 266 : 2.062982397485774\n",
      "epoch : 267 : 2.0629228360971537\n",
      "epoch : 268 : 2.062863764120743\n",
      "epoch : 269 : 2.0628051720964895\n",
      "epoch : 270 : 2.0627470508151178\n",
      "epoch : 271 : 2.0626893913107254\n",
      "epoch : 272 : 2.062632184853625\n",
      "epoch : 273 : 2.0625754229434197\n",
      "epoch : 274 : 2.0625190973023013\n",
      "epoch : 275 : 2.062463199868573\n",
      "epoch : 276 : 2.0624077227903723\n",
      "epoch : 277 : 2.062352658419602\n",
      "epoch : 278 : 2.062297999306056\n",
      "epoch : 279 : 2.062243738191728\n",
      "epoch : 280 : 2.0621898680053046\n",
      "epoch : 281 : 2.0621363818568357\n",
      "epoch : 282 : 2.062083273032565\n",
      "epoch : 283 : 2.062030534989932\n",
      "epoch : 284 : 2.061978161352724\n",
      "epoch : 285 : 2.061926145906381\n",
      "epoch : 286 : 2.0618744825934514\n",
      "epoch : 287 : 2.061823165509179\n",
      "epoch : 288 : 2.0617721888972365\n",
      "epoch : 289 : 2.0617215471455808\n",
      "epoch : 290 : 2.0616712347824424\n",
      "epoch : 291 : 2.061621246472433\n",
      "epoch : 292 : 2.061571577012775\n",
      "epoch : 293 : 2.0615222213296405\n",
      "epoch : 294 : 2.061473174474603\n",
      "epoch : 295 : 2.0614244316212016\n",
      "epoch : 296 : 2.0613759880615974\n",
      "epoch : 297 : 2.061327839203336\n",
      "epoch : 298 : 2.061279980566209\n",
      "epoch : 299 : 2.061232407779205\n",
      "epoch : 300 : 2.0611851165775463\n",
      "epoch : 301 : 2.0611381027998257\n",
      "epoch : 302 : 2.061091362385214\n",
      "epoch : 303 : 2.0610448913707566\n",
      "epoch : 304 : 2.060998685888751\n",
      "epoch : 305 : 2.060952742164191\n",
      "epoch : 306 : 2.060907056512297\n",
      "epoch : 307 : 2.060861625336109\n",
      "epoch : 308 : 2.0608164451241544\n",
      "epoch : 309 : 2.060771512448179\n",
      "epoch : 310 : 2.060726823960944\n",
      "epoch : 311 : 2.06068237639409\n",
      "epoch : 312 : 2.060638166556056\n",
      "epoch : 313 : 2.0605941913300607\n",
      "epoch : 314 : 2.0605504476721426\n",
      "epoch : 315 : 2.0605069326092496\n",
      "epoch : 316 : 2.0604636432373926\n",
      "epoch : 317 : 2.060420576719838\n",
      "epoch : 318 : 2.0603777302853623\n",
      "epoch : 319 : 2.06033510122655\n",
      "epoch : 320 : 2.060291235866681\n",
      "epoch : 321 : 2.06024787114813\n",
      "epoch : 322 : 2.0602047367204017\n",
      "epoch : 323 : 2.060161829331583\n",
      "epoch : 324 : 2.060119145814136\n",
      "epoch : 325 : 2.0600766830824373\n",
      "epoch : 326 : 2.060034438130392\n",
      "epoch : 327 : 2.0599924080291214\n",
      "epoch : 328 : 2.059950589924729\n",
      "epoch : 329 : 2.0599089810361253\n",
      "epoch : 330 : 2.05986757865293\n",
      "epoch : 331 : 2.059826380133434\n",
      "epoch : 332 : 2.0597853829026245\n",
      "epoch : 333 : 2.0597445844502706\n",
      "epoch : 334 : 2.059703982329071\n",
      "epoch : 335 : 2.059663574152851\n",
      "epoch : 336 : 2.0596233575948277\n",
      "epoch : 337 : 2.0595833303859084\n",
      "epoch : 338 : 2.0595434903130614\n",
      "epoch : 339 : 2.0595038352177215\n",
      "epoch : 340 : 2.0594643629942513\n",
      "epoch : 341 : 2.059425071588445\n",
      "epoch : 342 : 2.0593859589960806\n",
      "epoch : 343 : 2.0593470232615116\n",
      "epoch : 344 : 2.0593082624763066\n",
      "epoch : 345 : 2.059269674777923\n",
      "epoch : 346 : 2.0592312583484262\n",
      "epoch : 347 : 2.0591930114132437\n",
      "epoch : 348 : 2.059154932239957\n",
      "epoch : 349 : 2.0591170191371297\n",
      "epoch : 350 : 2.0590792704531697\n",
      "epoch : 351 : 2.0590416845752277\n",
      "epoch : 352 : 2.059004259928124\n",
      "epoch : 353 : 2.0589669949733116\n",
      "epoch : 354 : 2.0589298882078637\n",
      "epoch : 355 : 2.0588929381635\n",
      "epoch : 356 : 2.0588561434056327\n",
      "epoch : 357 : 2.0588195025324443\n",
      "epoch : 358 : 2.058783014173995\n",
      "epoch : 359 : 2.0587466769913525\n",
      "epoch : 360 : 2.058710489675744\n",
      "epoch : 361 : 2.058674450947745\n",
      "epoch : 362 : 2.058638559556476\n",
      "epoch : 363 : 2.058602814278837\n",
      "epoch : 364 : 2.058567213918751\n",
      "epoch : 365 : 2.058531757306442\n",
      "epoch : 366 : 2.0584964432977237\n",
      "epoch : 367 : 2.0584612707733148\n",
      "epoch : 368 : 2.0584262386381713\n",
      "epoch : 369 : 2.058391345820839\n",
      "epoch : 370 : 2.058356591272825\n",
      "epoch : 371 : 2.0583219739679843\n",
      "epoch : 372 : 2.058287492901929\n",
      "epoch : 373 : 2.0582531470914507\n",
      "epoch : 374 : 2.0582189355739593\n",
      "epoch : 375 : 2.0581848574069403\n",
      "epoch : 376 : 2.0581509116674255\n",
      "epoch : 377 : 2.0581170974514778\n",
      "epoch : 378 : 2.0580834138736956\n",
      "epoch : 379 : 2.058049860066723\n",
      "epoch : 380 : 2.0580164351807864\n",
      "epoch : 381 : 2.0579831383832246\n",
      "epoch : 382 : 2.0579499688580554\n",
      "epoch : 383 : 2.0579169258055368\n",
      "epoch : 384 : 2.057884008441748\n",
      "epoch : 385 : 2.05785121599818\n",
      "epoch : 386 : 2.057818547721342\n",
      "epoch : 387 : 2.0577860028723705\n",
      "epoch : 388 : 2.0577535807266574\n",
      "epoch : 389 : 2.057721280573484\n",
      "epoch : 390 : 2.057689101715667\n",
      "epoch : 391 : 2.057657043469213\n",
      "epoch : 392 : 2.0576251051629844\n",
      "epoch : 393 : 2.0575932861383723\n",
      "epoch : 394 : 2.0575615857489815\n",
      "epoch : 395 : 2.05753000336032\n",
      "epoch : 396 : 2.0574985383495017\n",
      "epoch : 397 : 2.057467190104954\n",
      "epoch : 398 : 2.0574359580261334\n",
      "epoch : 399 : 2.057404841523253\n",
      "epoch : 400 : 2.0573738400170107\n",
      "epoch : 401 : 2.057342952938332\n",
      "epoch : 402 : 2.0573121797281155\n",
      "epoch : 403 : 2.0572815198369843\n",
      "epoch : 404 : 2.057250972725048\n",
      "epoch : 405 : 2.0572205378616717\n",
      "epoch : 406 : 2.0571902147252414\n",
      "epoch : 407 : 2.0571600028029544\n",
      "epoch : 408 : 2.057129901590592\n",
      "epoch : 409 : 2.0570999105923224\n",
      "epoch : 410 : 2.0570700293204864\n",
      "epoch : 411 : 2.0570402572954096\n",
      "epoch : 412 : 2.057010594045201\n",
      "epoch : 413 : 2.056981039105571\n",
      "epoch : 414 : 2.0569515920196477\n",
      "epoch : 415 : 2.0569222523377997\n",
      "epoch : 416 : 2.056893019617461\n",
      "epoch : 417 : 2.0568638934229666\n",
      "epoch : 418 : 2.056834873325386\n",
      "epoch : 419 : 2.0568059589023644\n",
      "epoch : 420 : 2.056777149737969\n",
      "epoch : 421 : 2.0567484454225373\n",
      "epoch : 422 : 2.056719845552529\n",
      "epoch : 423 : 2.0566913497303836\n",
      "epoch : 424 : 2.056662957564383\n",
      "epoch : 425 : 2.0566346686685124\n",
      "epoch : 426 : 2.056606482662331\n",
      "epoch : 427 : 2.0565783991708417\n",
      "epoch : 428 : 2.056550417824369\n",
      "epoch : 429 : 2.05652253825843\n",
      "epoch : 430 : 2.0564947601136256\n",
      "epoch : 431 : 2.056467083035515\n",
      "epoch : 432 : 2.056439506674511\n",
      "epoch : 433 : 2.0564120306857636\n",
      "epoch : 434 : 2.056384654729059\n",
      "epoch : 435 : 2.0563573784687126\n",
      "epoch : 436 : 2.0563302015734646\n",
      "epoch : 437 : 2.0563031237163893\n",
      "epoch : 438 : 2.05627614457479\n",
      "epoch : 439 : 2.056249263830111\n",
      "epoch : 440 : 2.0562224811678425\n",
      "epoch : 441 : 2.0561957962774353\n",
      "epoch : 442 : 2.0561692088522117\n",
      "epoch : 443 : 2.0561427185892804\n",
      "epoch : 444 : 2.0561163251894565\n",
      "epoch : 445 : 2.0560900283571777\n",
      "epoch : 446 : 2.05606382780043\n",
      "epoch : 447 : 2.056037723230669\n",
      "epoch : 448 : 2.0560117143627448\n",
      "epoch : 449 : 2.055985800914833\n",
      "epoch : 450 : 2.055959982608359\n",
      "epoch : 451 : 2.0559342591679353\n",
      "epoch : 452 : 2.0559086303212877\n",
      "epoch : 453 : 2.0558830957991954\n",
      "epoch : 454 : 2.0558576553354238\n",
      "epoch : 455 : 2.0558323086666634\n",
      "epoch : 456 : 2.055807055532469\n",
      "epoch : 457 : 2.0557818956752025\n",
      "epoch : 458 : 2.05575682883997\n",
      "epoch : 459 : 2.055731854774572\n",
      "epoch : 460 : 2.0557069732294417\n",
      "epoch : 461 : 2.0556821839575994\n",
      "epoch : 462 : 2.0556574867145923\n",
      "epoch : 463 : 2.05563288125845\n",
      "epoch : 464 : 2.0556083673496293\n",
      "epoch : 465 : 2.05558394475097\n",
      "epoch : 466 : 2.055559613227646\n",
      "epoch : 467 : 2.05553537254712\n",
      "epoch : 468 : 2.055511222479096\n",
      "epoch : 469 : 2.0554871627954783\n",
      "epoch : 470 : 2.055463193270325\n",
      "epoch : 471 : 2.055439313679814\n",
      "epoch : 472 : 2.055415523802191\n",
      "epoch : 473 : 2.0553918234177377\n",
      "epoch : 474 : 2.0553682123087316\n",
      "epoch : 475 : 2.055344690259405\n",
      "epoch : 476 : 2.055321257055912\n",
      "epoch : 477 : 2.0552979124862882\n",
      "epoch : 478 : 2.055274656340421\n",
      "epoch : 479 : 2.055251488410007\n",
      "epoch : 480 : 2.0552284084885266\n",
      "epoch : 481 : 2.0552054163712064\n",
      "epoch : 482 : 2.0551825118549893\n",
      "epoch : 483 : 2.055159694738499\n",
      "epoch : 484 : 2.0551369648220166\n",
      "epoch : 485 : 2.055114321907444\n",
      "epoch : 486 : 2.0550917657982777\n",
      "epoch : 487 : 2.0550692962995813\n",
      "epoch : 488 : 2.055046913217955\n",
      "epoch : 489 : 2.0550246163615107\n",
      "epoch : 490 : 2.0550024055398435\n",
      "epoch : 491 : 2.054980280564007\n",
      "epoch : 492 : 2.054958241246488\n",
      "epoch : 493 : 2.054936287401182\n",
      "epoch : 494 : 2.0549144188433672\n",
      "epoch : 495 : 2.0548926353896824\n",
      "epoch : 496 : 2.0548709368581033\n",
      "epoch : 497 : 2.05484932306792\n",
      "epoch : 498 : 2.0548277938397157\n",
      "epoch : 499 : 2.0548063489953443\n",
      "Last MSE : 2.054784988357908\n"
     ]
    }
   ],
   "source": [
    "inp=testInputs[:20]\n",
    "testweights1,testbias1,testweights2,testbias2,testweights3,testbias3=training(500,inp,y_testput,fixedtestweights1,fixedtestbias1,fixedtestweights2,fixedtestbias2,fixedtestweights3,fixedtestbias3,f1,f2)\n",
    "testoutputs1,testoutputs2,testoutputs3=forward(testInputs,testweights1,testbias1,testweights2,testbias2,testweights3,testbias3,f1,f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d5001b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.11109449  0.18407236 -0.06183093  0.18831472  0.01587429  0.08944852\n",
      " -0.00258727  0.10145389  0.05551158  0.03549759]\n",
      "[0.09444248 0.23185036 0.03639032 0.15621071 0.18213564 0.07915895\n",
      " 0.04081246 0.08410352 0.059006   0.15050797]\n"
     ]
    }
   ],
   "source": [
    "print(testoutputs3[0])\n",
    "print(testoutputs3[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bd32e5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : 3, reel : 0\n",
      "Pred : 1, reel : 1\n",
      "Pred : 0, reel : 2\n",
      "Pred : 0, reel : 3\n",
      "Pred : 3, reel : 4\n",
      "Pred : 1, reel : 5\n",
      "Pred : 0, reel : 6\n",
      "Pred : 3, reel : 7\n",
      "Pred : 3, reel : 8\n",
      "Pred : 1, reel : 9\n",
      "Pred : 3, reel : 0\n",
      "Pred : 1, reel : 1\n",
      "Pred : 0, reel : 2\n",
      "Pred : 0, reel : 3\n",
      "Pred : 3, reel : 4\n",
      "Pred : 1, reel : 5\n",
      "Pred : 0, reel : 6\n",
      "Pred : 3, reel : 7\n",
      "Pred : 3, reel : 8\n",
      "Pred : 1, reel : 9\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "true=0\n",
    "for out in range(len(inp)):\n",
    "    print(f\"Pred : {np.argmax(testoutputs3[out])}, reel : {np.argmax(y_testput[out])}\")\n",
    "    if np.argmax(testoutputs3[out])==np.argmax(y_testput[out]):\n",
    "        true+=1\n",
    "print(true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
